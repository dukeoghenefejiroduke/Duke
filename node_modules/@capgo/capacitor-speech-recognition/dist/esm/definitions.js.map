{"version":3,"file":"definitions.js","sourceRoot":"","sources":["../../src/definitions.ts"],"names":[],"mappings":"","sourcesContent":["import type { PermissionState, PluginListenerHandle } from '@capacitor/core';\n\n/**\n * Permission map returned by `checkPermissions` and `requestPermissions`.\n *\n * On Android the state maps to the `RECORD_AUDIO` permission.\n * On iOS it combines speech recognition plus microphone permission.\n */\nexport interface SpeechRecognitionPermissionStatus {\n  speechRecognition: PermissionState;\n}\n\n/**\n * Configure how the recognizer behaves when calling {@link SpeechRecognitionPlugin.start}.\n */\nexport interface SpeechRecognitionStartOptions {\n  /**\n   * Locale identifier such as `en-US`. When omitted the device language is used.\n   */\n  language?: string;\n  /**\n   * Maximum number of final matches returned by native APIs. Defaults to `5`.\n   */\n  maxResults?: number;\n  /**\n   * Prompt message shown inside the Android system dialog (ignored on iOS).\n   */\n  prompt?: string;\n  /**\n   * When `true`, Android shows the OS speech dialog instead of running inline recognition.\n   * Defaults to `false`.\n   */\n  popup?: boolean;\n  /**\n   * Emits partial transcription updates through the `partialResults` listener while audio is captured.\n   */\n  partialResults?: boolean;\n  /**\n   * Enables native punctuation handling where supported (iOS 16+).\n   */\n  addPunctuation?: boolean;\n  /**\n   * Allow a number of milliseconds of silence before splitting the recognition session into segments.\n   * Required to be greater than zero and currently supported on Android only.\n   */\n  allowForSilence?: number;\n}\n\n/**\n * Raised whenever a partial transcription is produced.\n */\nexport interface SpeechRecognitionPartialResultEvent {\n  matches: string[];\n}\n\n/**\n * Raised whenever a segmented result is produced (Android only).\n */\nexport interface SpeechRecognitionSegmentResultEvent {\n  matches: string[];\n}\n\n/**\n * Raised when the listening state changes.\n */\nexport interface SpeechRecognitionListeningEvent {\n  status: 'started' | 'stopped';\n}\n\nexport interface SpeechRecognitionAvailability {\n  available: boolean;\n}\n\nexport interface SpeechRecognitionMatches {\n  matches?: string[];\n}\n\nexport interface SpeechRecognitionLanguages {\n  languages: string[];\n}\n\nexport interface SpeechRecognitionListening {\n  listening: boolean;\n}\n\nexport interface SpeechRecognitionPlugin {\n  /**\n   * Checks whether the native speech recognition service is usable on the current device.\n   */\n  available(): Promise<SpeechRecognitionAvailability>;\n  /**\n   * Begins capturing audio and transcribing speech.\n   *\n   * When `partialResults` is `true`, the returned promise resolves immediately and updates are\n   * streamed through the `partialResults` listener until {@link stop} is called.\n   */\n  start(options?: SpeechRecognitionStartOptions): Promise<SpeechRecognitionMatches>;\n  /**\n   * Stops listening and tears down native resources.\n   */\n  stop(): Promise<void>;\n  /**\n   * Gets the locales supported by the underlying recognizer.\n   *\n   * Android 13+ devices no longer expose this list; in that case `languages` is empty.\n   */\n  getSupportedLanguages(): Promise<SpeechRecognitionLanguages>;\n  /**\n   * Returns whether the plugin is actively listening for speech.\n   */\n  isListening(): Promise<SpeechRecognitionListening>;\n  /**\n   * Gets the current permission state.\n   */\n  checkPermissions(): Promise<SpeechRecognitionPermissionStatus>;\n  /**\n   * Requests the microphone + speech recognition permissions.\n   */\n  requestPermissions(): Promise<SpeechRecognitionPermissionStatus>;\n  /**\n   * Returns the native plugin version bundled with this package.\n   *\n   * Useful when reporting issues to confirm that native and JS versions match.\n   */\n  getPluginVersion(): Promise<{ version: string }>;\n  /**\n   * Listen for segmented session completion events (Android only).\n   */\n  addListener(eventName: 'endOfSegmentedSession', listenerFunc: () => void): Promise<PluginListenerHandle>;\n  /**\n   * Listen for segmented recognition results (Android only).\n   */\n  addListener(\n    eventName: 'segmentResults',\n    listenerFunc: (event: SpeechRecognitionSegmentResultEvent) => void,\n  ): Promise<PluginListenerHandle>;\n  /**\n   * Listen for partial transcription updates emitted while `partialResults` is enabled.\n   */\n  addListener(\n    eventName: 'partialResults',\n    listenerFunc: (event: SpeechRecognitionPartialResultEvent) => void,\n  ): Promise<PluginListenerHandle>;\n  /**\n   * Listen for changes to the native listening state.\n   */\n  addListener(\n    eventName: 'listeningState',\n    listenerFunc: (event: SpeechRecognitionListeningEvent) => void,\n  ): Promise<PluginListenerHandle>;\n  /**\n   * Removes every registered listener.\n   */\n  removeAllListeners(): Promise<void>;\n}\n"]}